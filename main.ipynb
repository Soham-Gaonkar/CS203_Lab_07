{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python implementation: CPython\n",
      "Python version       : 3.12.5\n",
      "IPython version      : 9.0.2\n",
      "\n",
      "numpy       : 2.2.3\n",
      "matplotlib  : 3.10.1\n",
      "sklearn     : 1.6.1\n",
      "pandas      : 2.2.3\n",
      "torch       : 2.6.0\n",
      "transformers: 4.49.0\n",
      "\n",
      "Compiler    : MSC v.1940 64 bit (AMD64)\n",
      "OS          : Windows\n",
      "Release     : 11\n",
      "Machine     : AMD64\n",
      "Processor   : Intel64 Family 6 Model 154 Stepping 3, GenuineIntel\n",
      "CPU cores   : 12\n",
      "Architecture: 64bit\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%reload_ext watermark\n",
    "%watermark -v -m -p numpy,matplotlib,sklearn,pandas,torch,transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import random\n",
    "import torch\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>graphic sex may be what 's attracting audience...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>perhaps the grossest movie ever made</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the film is moody , oozing , chilling and hear...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>watching the chemistry between freeman and jud...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the wonderfully lush morvern callar is pure pu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  graphic sex may be what 's attracting audience...      1\n",
       "1               perhaps the grossest movie ever made      0\n",
       "2  the film is moody , oozing , chilling and hear...      1\n",
       "3  watching the chemistry between freeman and jud...      1\n",
       "4  the wonderfully lush morvern callar is pure pu...      1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "train_df = pd.read_csv('data/train_split.tsv', sep='\\t')\n",
    "test_df = pd.read_csv('data/test.tsv', sep='\\t', header=None, names=['text', 'label'])\n",
    "val_df = pd.read_csv('data/val_split.tsv', sep='\\t')\n",
    "\n",
    "# test_df.head()\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP_Model(\n",
      "  (layers): ModuleDict(\n",
      "    (Layer 1): Sequential(\n",
      "      (0): Linear(in_features=10000, out_features=512, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Dropout(p=0.3, inplace=False)\n",
      "    )\n",
      "    (Layer 2): Sequential(\n",
      "      (0): Linear(in_features=512, out_features=256, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Dropout(p=0.3, inplace=False)\n",
      "    )\n",
      "    (Layer 3): Sequential(\n",
      "      (0): Linear(in_features=256, out_features=128, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Dropout(p=0.3, inplace=False)\n",
      "    )\n",
      "    (Layer 4): Sequential(\n",
      "      (0): Linear(in_features=128, out_features=64, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Dropout(p=0.3, inplace=False)\n",
      "    )\n",
      "    (Layer 5): Linear(in_features=64, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MLP_Model(nn.Module):\n",
    "    def __init__(self, input_size=10000, hidden_sizes=[512, 256, 128, 64], output_size=2, dropout_rate=0.3):\n",
    "        super(MLP_Model, self).__init__()\n",
    "\n",
    "        self.layers = nn.ModuleDict({\n",
    "            \"Layer 1\": nn.Sequential(\n",
    "                nn.Linear(input_size, hidden_sizes[0]),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout_rate)\n",
    "            ),\n",
    "            \"Layer 2\": nn.Sequential(\n",
    "                nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout_rate)\n",
    "            ),\n",
    "            \"Layer 3\": nn.Sequential(\n",
    "                nn.Linear(hidden_sizes[1], hidden_sizes[2]),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout_rate)\n",
    "            ),\n",
    "            \"Layer 4\": nn.Sequential(\n",
    "                nn.Linear(hidden_sizes[2], hidden_sizes[3]),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout_rate)\n",
    "            ),\n",
    "            \"Layer 5\": nn.Linear(hidden_sizes[3], output_size)\n",
    "        })\n",
    "\n",
    "    def forward(self, x):\n",
    "        for name, layer in self.layers.items():\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "model = MLP_Model()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: layers.Layer 1.0.weight | Size: torch.Size([512, 10000]) | Params: 5120000 | Trainable: True\n",
      "Layer: layers.Layer 1.0.bias | Size: torch.Size([512]) | Params: 512 | Trainable: True\n",
      "Layer: layers.Layer 2.0.weight | Size: torch.Size([256, 512]) | Params: 131072 | Trainable: True\n",
      "Layer: layers.Layer 2.0.bias | Size: torch.Size([256]) | Params: 256 | Trainable: True\n",
      "Layer: layers.Layer 3.0.weight | Size: torch.Size([128, 256]) | Params: 32768 | Trainable: True\n",
      "Layer: layers.Layer 3.0.bias | Size: torch.Size([128]) | Params: 128 | Trainable: True\n",
      "Layer: layers.Layer 4.0.weight | Size: torch.Size([64, 128]) | Params: 8192 | Trainable: True\n",
      "Layer: layers.Layer 4.0.bias | Size: torch.Size([64]) | Params: 64 | Trainable: True\n",
      "Layer: layers.Layer 5.weight | Size: torch.Size([2, 64]) | Params: 128 | Trainable: True\n",
      "Layer: layers.Layer 5.bias | Size: torch.Size([2]) | Params: 2 | Trainable: True\n",
      "Total Trainable Parameters: 5293122\n"
     ]
    }
   ],
   "source": [
    "sum_params = 0\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(f'Layer: {name} | Size: {param.size()} | Params: {param.numel()} | Trainable: {param.requires_grad}')\n",
    "    if param.requires_grad:\n",
    "        sum_params += param.numel()\n",
    "\n",
    "print(f'Total Trainable Parameters: {sum_params}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag-of-words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bag-of-words model (BoW) is a model of text which uses an unordered collection (a \"bag\") of words. It disregards word order (and thus most of syntax or grammar) but captures multiplicity.\n",
    "\n",
    "Each key is the word, and each value is the number of occurrences of that word in the given text document.\n",
    "\n",
    "```javascript\n",
    "(1) John likes to watch movies. Mary likes movies too.\n",
    "\n",
    "(2) Mary also likes to watch football games.\n",
    "```\n",
    "\n",
    "Based on these two text documents, a list is constructed as follows for each document:\n",
    "\n",
    "```javascript\n",
    "\"John\",\"likes\",\"to\",\"watch\",\"movies\",\"Mary\",\"likes\",\"movies\",\"too\"\n",
    "\n",
    "\"Mary\",\"also\",\"likes\",\"to\",\"watch\",\"football\",\"games\"\n",
    "```\n",
    "\n",
    "Representing each bag-of-words as a JSON object, and attributing to the respective JavaScript variable:\n",
    "\n",
    "```javascript\n",
    "BoW1 = {\"John\":1,\"likes\":2,\"to\":1,\"watch\":1,\"movies\":2,\"Mary\":1,\"too\":1};\n",
    "\n",
    "BoW2 = {\"Mary\":1,\"also\":1,\"likes\":1,\"to\":1,\"watch\":1,\"football\":1,\"games\":1};\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5536 1384 1821\n",
      "torch.Size([5536, 10000]) torch.Size([1384, 10000]) torch.Size([1821, 10000])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import torch\n",
    "\n",
    "vectorizer = CountVectorizer(max_features=10000)\n",
    "\n",
    "X_train_bow = vectorizer.fit_transform(train_df.text)\n",
    "X_val_bow = vectorizer.transform(val_df.text)\n",
    "X_test_bow = vectorizer.transform(test_df.text)\n",
    "\n",
    "y_train = train_df.label\n",
    "y_val = val_df.label\n",
    "y_test = test_df.label\n",
    "\n",
    "#convert to torch tensor\n",
    "X_train_bow = torch.tensor(X_train_bow.toarray(), dtype=torch.float32)\n",
    "X_val_bow = torch.tensor(X_val_bow.toarray(), dtype=torch.float32)\n",
    "X_test_bow = torch.tensor(X_test_bow.toarray(), dtype=torch.float32)\n",
    "\n",
    "y_train = torch.tensor(y_train.values, dtype=torch.int32)\n",
    "y_val = torch.tensor(y_val.values, dtype=torch.int32)\n",
    "y_test = torch.tensor(y_test.values, dtype=torch.int32)\n",
    "\n",
    "# df shape\n",
    "print(len(train_df), len(val_df), len(test_df)) \n",
    "print(X_train_bow.shape, X_val_bow.shape, X_test_bow.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Sentence: ['graphic', 'sex', 'may', 'be', 'what', \"'s\", 'attracting', 'audiences', 'to', 'unfaithful', ',', 'but', 'gripping', 'performances', 'by', 'lane', 'and', 'gere', 'are', 'what', 'will', 'keep', 'them', 'awake']\n",
      "Non-zero indices: [ 259  321  399  419  485  751  757 3447 3619 3669 4863 5012 5569 6737\n",
      " 8445 9314 9393 9589 9837 9870]\n",
      "Words in BoW representation: ['and', 'are', 'audiences', 'awake', 'be', 'but', 'by', 'gere', 'graphic', 'gripping', 'keep', 'lane', 'may', 'performances', 'sex', 'them', 'to', 'unfaithful', 'what', 'will']\n",
      "Original words in sentences sorted : [\"'s\", ',', 'and', 'are', 'attracting', 'audiences', 'awake', 'be', 'but', 'by', 'gere', 'graphic', 'gripping', 'keep', 'lane', 'may', 'performances', 'sex', 'them', 'to', 'unfaithful', 'what', 'what', 'will']\n",
      "24\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "word2idx = vectorizer.vocabulary_\n",
    "idx2word = {v: k for k, v in word2idx.items()}\n",
    "\n",
    "print(\"Original Sentence:\", train_df.text.iloc[0].split())\n",
    "\n",
    "nonzero_indices = X_train_bow[0].nonzero().flatten().numpy()\n",
    "print(\"Non-zero indices:\", nonzero_indices)\n",
    "\n",
    "words_in_sentence = [idx2word[idx] for idx in nonzero_indices]\n",
    "print(\"Words in BoW representation:\", words_in_sentence)\n",
    "\n",
    "print(\"Original words in sentences sorted :\", sorted(train_df.text.iloc[0].split()))\n",
    "print(len(train_df.text.iloc[0].split()))\n",
    "print(len(words_in_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'graphic': np.int64(3619), 'sex': np.int64(8445), 'may': np.int64(5569), 'be': np.int64(485), 'what': np.int64(9837), 'audiences': np.int64(399), 'to': np.int64(9393), 'unfaithful': np.int64(9589), 'but': np.int64(751), 'gripping': np.int64(3669)}\n"
     ]
    }
   ],
   "source": [
    "print({k: vectorizer.vocabulary_[k] for k in list(vectorizer.vocabulary_)[:10]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(len(vectorizer.vocabulary_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Embedding Model bert-base-uncased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\UserFiles\\CS203_Lab_07\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertTokenizerFast(name_or_path='bert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
      "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "}\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "model_name = 'bert-base-uncased'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "print(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertModel(\n",
      "  (embeddings): BertEmbeddings(\n",
      "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "    (position_embeddings): Embedding(512, 768)\n",
      "    (token_type_embeddings): Embedding(2, 768)\n",
      "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (encoder): BertEncoder(\n",
      "    (layer): ModuleList(\n",
      "      (0-11): 12 x BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSdpaSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pooler): BertPooler(\n",
      "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (activation): Tanh()\n",
      "  )\n",
      ")\n",
      "Embedding size: 768\n"
     ]
    }
   ],
   "source": [
    "bert = AutoModel.from_pretrained(model_name)\n",
    "print(bert)\n",
    "\n",
    "embedding_size = bert.config.hidden_size\n",
    "print('Embedding size:',embedding_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 101, 7592, 2088,  102]])\n",
      "['[CLS]', 'hello', 'world', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "bert.eval()\n",
    "bert.to(device)\n",
    "\n",
    "text = 'hello world'\n",
    "inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True)\n",
    "print(inputs['input_ids'])\n",
    "print(tokenizer.convert_ids_to_tokens(inputs['input_ids'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First id: tensor(7592)\n",
      "First token: hello\n",
      "Embedding shape: torch.Size([1, 4, 768])\n",
      "Sentence embedding shape: torch.Size([1, 768])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = bert(**inputs.to(device))\n",
    "\n",
    "embeddings = outputs.last_hidden_state\n",
    "print('First id:',inputs['input_ids'][0][1])\n",
    "print('First token:',tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])[1])\n",
    "# print('First embedding:',embeddings[0][0])\n",
    "print('Embedding shape:',embeddings.shape)\n",
    "\n",
    "\n",
    "sentence_embeddings = torch.mean(embeddings, dim=1)\n",
    "print('Sentence embedding shape:',sentence_embeddings.shape)\n",
    "\n",
    "# CLS : first token, SEP : last token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1384, 768])\n"
     ]
    }
   ],
   "source": [
    "def get_bert_embeddings(text, tokenizer, bert, device):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()} \n",
    "    with torch.no_grad():\n",
    "        outputs = bert(**inputs)\n",
    "    embeddings = outputs.last_hidden_state\n",
    "    sentence_embeddings = torch.mean(embeddings, dim=1)  # Mean pooling\n",
    "    return sentence_embeddings.cpu().numpy()\n",
    "\n",
    "X_val_texts = val_df[\"text\"].tolist()\n",
    "X_val_bert = get_bert_embeddings(X_val_texts, tokenizer, bert, device)\n",
    "X_val_bert = torch.tensor(X_val_bert, dtype=torch.float32)\n",
    "print(X_val_bert.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5536, 768])\n"
     ]
    }
   ],
   "source": [
    "X_train_texts = train_df[\"text\"].tolist()\n",
    "X_train_bert = get_bert_embeddings(X_train_texts, tokenizer, bert, device)\n",
    "X_train_bert = torch.tensor(X_train_bert, dtype=torch.float32)\n",
    "print(X_train_bert.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1821, 768])\n"
     ]
    }
   ],
   "source": [
    "X_test_texts = test_df[\"text\"].tolist()\n",
    "X_test_bert = get_bert_embeddings(X_test_texts, tokenizer, bert, device)\n",
    "X_test_bert = torch.tensor(X_test_bert, dtype=torch.float32)\n",
    "print(X_test_bert.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5536]) torch.Size([1384]) torch.Size([1821])\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape, y_val.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "def train(model , optimizer , criterion, X_train , y_train , X_val , y_val):\n",
    "    model.train()\n",
    "    best_loss = float('inf')\n",
    "    loss_val = 0\n",
    "    train_loss_history = []\n",
    "    val_loss_history = []\n",
    "\n",
    "    for epoch in range(10):\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        X_train = torch.tensor(X_train , dtype = torch.float32).to(device)\n",
    "        y_train = torch.tensor(y_train , dtype = torch.int64).to(device)\n",
    "        X_val = torch.tensor(X_val , dtype = torch.float32).to(device)\n",
    "        y_val = torch.tensor(y_val , dtype = torch.int64).to(device)\n",
    "\n",
    "        y_pred = model(X_train)\n",
    "        loss = criterion(y_pred, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f'Epoch: {epoch} | Loss: {loss.item()}')\n",
    "\n",
    "        model.eval()\n",
    "        y_pred_val = model(X_val)\n",
    "        loss_val = criterion(y_pred_val, y_val)\n",
    "        print(f'Epoch: {epoch} | Loss Val: {loss_val.item()}')\n",
    "\n",
    "        train_loss_history.append(loss.item())\n",
    "        val_loss_history.append(loss_val.item())\n",
    "\n",
    "        # save the best model checkpoint.pt file\n",
    "        if epoch == 0:\n",
    "            best_loss = loss_val\n",
    "            torch.save(model.state_dict(), 'models/checkpoint.pt')\n",
    "        else:\n",
    "            if loss_val < best_loss:\n",
    "                best_loss = loss_val\n",
    "                torch.save(model.state_dict(), 'models/checkpoint.pt')\n",
    "\n",
    "    return train_loss_history, val_loss_history\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_model = MLP_Model(input_size=10000)\n",
    "bow_model.to(device)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
